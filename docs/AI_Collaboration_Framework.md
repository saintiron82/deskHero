# AI 협업 프레임워크: 가설-검증 기반 문제 해결

## 개요

본 문서는 AI를 "코드 생성기"가 아닌 **"연구 파트너"**로 활용하는 방법론을 정리합니다.
단순 질의응답이 아닌, 복잡한 문제를 AI와 함께 체계적으로 해결하는 프레임워크입니다.

---

## 핵심 원칙

### 1. AI는 실행자가 아닌 분석자

```
❌ 기존: "이거 고쳐줘" → AI가 추측으로 수정
✅ 제안: "이 데이터를 분석하고 원인을 찾아줘" → AI가 근거 기반 진단
```

AI에게 **결과물**을 요청하지 말고 **분석**을 요청하세요.

### 2. 측정 가능한 성공 기준 제시

```
❌ 모호함: "성능 개선해줘"
✅ 명확함: "응답 시간 200ms 이하로 줄여줘"

❌ 모호함: "밸런스 맞춰줘"
✅ 명확함: "최고/최저 비율이 1.3 이하가 되어야 해"
```

AI가 스스로 **성공/실패를 판단**할 수 있어야 반복 개선이 가능합니다.

### 3. 검증 수단 확보

AI의 제안을 **즉시 검증할 수 있는 환경**이 필요합니다:

| 도메인 | 검증 수단 |
|--------|----------|
| 게임 밸런스 | 헤드리스 시뮬레이터 |
| API 성능 | 벤치마크 스크립트 |
| UI/UX | 자동화 테스트 |
| 알고리즘 | 단위 테스트 |
| 데이터 분석 | 검증 데이터셋 |

---

## 프레임워크 구조

```
┌─────────────────────────────────────────────────────────────┐
│                    AI 협업 사이클                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   ┌──────────┐    ┌──────────┐    ┌──────────┐             │
│   │  1.정의   │───▶│  2.분석   │───▶│  3.가설   │             │
│   │ (인간)   │    │  (AI)    │    │  (AI)    │             │
│   └──────────┘    └──────────┘    └──────────┘             │
│                                         │                   │
│   ┌──────────┐    ┌──────────┐    ┌─────▼────┐             │
│   │  6.적용   │◀───│  5.판단   │◀───│  4.검증   │             │
│   │ (AI+인간) │    │ (인간)   │    │  (자동)   │             │
│   └──────────┘    └──────────┘    └──────────┘             │
│        │                                ▲                   │
│        └────────── 반복 ────────────────┘                   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 단계별 상세

#### 1단계: 문제 정의 (인간)

**역할:** 목표와 제약 조건 명확화

```markdown
## 문제 정의 템플릿

### 현재 상태
- [측정 가능한 현재 수치/상태]

### 목표 상태
- [측정 가능한 목표 수치/상태]

### 제약 조건
- [변경 불가능한 것들]
- [반드시 유지해야 하는 것들]

### 성공 기준
- [조건 1]: [측정 방법]
- [조건 2]: [측정 방법]
```

**예시:**
```markdown
### 현재 상태
- API 응답 시간: 평균 850ms, P99 2.3초

### 목표 상태
- API 응답 시간: 평균 200ms 이하, P99 500ms 이하

### 제약 조건
- 기존 API 인터페이스 변경 불가
- PostgreSQL 유지 (DB 변경 불가)

### 성공 기준
- 평균 응답 시간 < 200ms (k6 벤치마크 기준)
- P99 응답 시간 < 500ms
- 기존 테스트 100% 통과
```

#### 2단계: 현황 분석 (AI)

**역할:** 데이터 수집 및 현황 파악

AI에게 요청할 것:
- 관련 코드/데이터 탐색
- 현재 상태 측정
- 병목 지점 식별
- 패턴 발견

```
프롬프트 예시:
"현재 API 응답 시간이 느린 원인을 분석해줘.
- 관련 코드를 찾아서 읽어줘
- 쿼리 실행 계획을 분석해줘
- 병목이 어디인지 데이터로 보여줘"
```

#### 3단계: 가설 수립 (AI)

**역할:** 원인 추정 및 해결책 제안

AI가 제시해야 할 것:
- 근본 원인 추정 (데이터 기반)
- 해결 옵션들 (장단점 포함)
- 예상 효과

```
좋은 가설 형식:
"[원인]이 문제라면, [조치]를 하면 [예상 결과]가 나올 것이다.
검증 방법: [구체적인 테스트 방법]"
```

#### 4단계: 검증 (자동화)

**역할:** 가설을 데이터로 검증

핵심 원칙:
- **자동화된 검증** (수동 확인 최소화)
- **빠른 피드백** (가능한 빨리 결과 확인)
- **병렬 실행** (독립적인 테스트는 동시 실행)

```bash
# 병렬 검증 예시
test_option_a &
test_option_b &
test_option_c &
wait
```

#### 5단계: 판단 (인간)

**역할:** 결과 해석 및 방향 결정

인간이 판단할 것:
- 목표 달성 여부
- 제약 조건 준수 여부
- 다음 단계 선택

```
판단 분기:
- 목표 달성 → 6단계로
- 부분 달성 → 가설 수정 후 3단계로
- 실패 → 분석 보완 후 2단계로
```

#### 6단계: 적용 (AI + 인간)

**역할:** 검증된 변경사항 적용

적용 순서:
1. AI가 코드 변경 생성
2. 인간이 리뷰 및 승인
3. 실험 환경에서 최종 검증
4. 프로덕션 적용

---

## 실전 패턴

### 패턴 1: 근본 원인 추적 (5 Whys with AI)

```
증상: "사용자가 로그인 못함"
  ↓ Why?
원인1: "세션 토큰이 만료됨"
  ↓ Why?
원인2: "토큰 갱신이 실패함"
  ↓ Why?
원인3: "갱신 API가 타임아웃"
  ↓ Why?
원인4: "DB 커넥션 풀 고갈"
  ↓ Why?
근본원인: "커넥션 누수 버그"
```

AI에게 각 단계에서 **코드/로그/데이터를 찾아 검증**하도록 요청

### 패턴 2: A/B 가설 비교

```
가설 A: "인덱스 추가로 해결"
  - 예상 효과: 쿼리 50% 개선
  - 비용: 저장 공간 증가

가설 B: "캐시 레이어 추가"
  - 예상 효과: 응답 80% 개선
  - 비용: 복잡도 증가

→ 둘 다 검증 후 데이터로 결정
```

### 패턴 3: 점진적 수렴

```
반복 1: 큰 방향 결정 (50% 개선)
반복 2: 세부 튜닝 (추가 30% 개선)
반복 3: 엣지 케이스 처리 (추가 10% 개선)
반복 4: 목표 도달 확인
```

### 패턴 4: 병렬 탐색

독립적인 가설들은 **동시에 검증**:

```
┌─ 가설 A 검증 ─┐
│               │
├─ 가설 B 검증 ─┼─▶ 결과 비교 ─▶ 최선 선택
│               │
└─ 가설 C 검증 ─┘
```

---

## 역할 분담 매트릭스

| 활동 | 인간 | AI | 자동화 |
|------|:----:|:--:|:------:|
| 목표 정의 | ● | ○ | - |
| 제약 조건 설정 | ● | ○ | - |
| 코드/데이터 탐색 | ○ | ● | - |
| 패턴 발견 | ○ | ● | - |
| 가설 수립 | ○ | ● | - |
| 테스트 실행 | - | ○ | ● |
| 결과 해석 | ○ | ● | - |
| 방향 결정 | ● | ○ | - |
| 코드 생성 | - | ● | - |
| 코드 리뷰 | ● | ○ | - |
| 최종 승인 | ● | - | - |

● 주도 / ○ 보조 / - 미참여

---

## 프롬프트 템플릿

### 분석 요청

```
[컨텍스트]
- 현재 상황: {상황 설명}
- 목표: {달성하고자 하는 것}
- 제약: {변경 불가능한 것}

[요청]
관련 코드/데이터를 찾아서 분석하고:
1. 현재 상태를 수치로 보여줘
2. 병목/문제 지점을 식별해줘
3. 가능한 원인들을 나열해줘
```

### 가설 검증 요청

```
[가설]
{원인}이 문제라면, {조치}를 하면 {예상 결과}가 나올 것이다.

[요청]
1. 이 가설을 검증할 수 있는 테스트를 설계해줘
2. 테스트를 실행해줘
3. 결과가 가설을 지지하는지 분석해줘
```

### 옵션 비교 요청

```
[상황]
{문제 설명}

[요청]
해결 옵션들을 제시하고 각각에 대해:
1. 예상 효과
2. 구현 난이도
3. 리스크
4. 검증 방법
을 분석해줘
```

### 병렬 실행 요청

```
다음 테스트들을 병렬로 실행해줘:
- 테스트 A: {설명}
- 테스트 B: {설명}
- 테스트 C: {설명}

모든 결과가 나오면 비교 분석해줘.
```

---

## 적용 가능 도메인

| 도메인 | 검증 수단 | 성공 기준 예시 |
|--------|----------|---------------|
| 성능 최적화 | 벤치마크 | 응답 시간, 처리량 |
| 버그 수정 | 테스트 스위트 | 테스트 통과율 |
| 게임 밸런스 | 시뮬레이터 | 지배율, 승률 |
| ML 모델 | 검증 데이터셋 | 정확도, F1 |
| UI/UX | E2E 테스트 | 전환율, 이탈률 |
| 보안 | 스캐너/펜테스트 | 취약점 수 |
| 인프라 | 모니터링 | 가용성, 레이턴시 |

---

## 안티패턴

### ❌ 피해야 할 것

1. **모호한 요청**
   ```
   ❌ "이거 좀 개선해줘"
   ✅ "응답 시간을 200ms 이하로 줄여줘"
   ```

2. **검증 없는 적용**
   ```
   ❌ AI 제안 → 바로 프로덕션 적용
   ✅ AI 제안 → 테스트 → 검증 → 적용
   ```

3. **단일 가설 집착**
   ```
   ❌ 하나의 해결책만 시도
   ✅ 여러 가설 병렬 검증 후 최선 선택
   ```

4. **수동 검증**
   ```
   ❌ "한번 실행해보고 눈으로 확인"
   ✅ 자동화된 테스트로 반복 검증
   ```

5. **결과물만 요청**
   ```
   ❌ "코드 짜줘"
   ✅ "원인 분석하고 해결책 제안해줘"
   ```

---

## 체크리스트

프로젝트 시작 전:

- [ ] 측정 가능한 성공 기준이 있는가?
- [ ] 자동화된 검증 수단이 있는가?
- [ ] 실험 환경이 프로덕션과 분리되어 있는가?

AI 협업 중:

- [ ] AI에게 분석을 요청하고 있는가? (결과물이 아닌)
- [ ] 가설을 데이터로 검증하고 있는가?
- [ ] 병렬 실행 가능한 것은 병렬로 하고 있는가?

적용 전:

- [ ] 검증 결과가 성공 기준을 만족하는가?
- [ ] 제약 조건을 위반하지 않았는가?
- [ ] 인간이 최종 리뷰했는가?

---

*이 프레임워크는 DeskWarrior 게임 밸런스 프로젝트에서 검증되었습니다.*
*2,360배의 밸런스 개선을 2시간 만에 달성한 방법론입니다.*
